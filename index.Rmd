---
title: "Sesión 4"
output:
  bookdown::html_document2:
    code_folding: hide 
    toc: true
    toc_float: true
bibliography: references.bib
#zotero: true
---

<center>

<img src="https://github.com/Estadistica-AnalisisPolitico/Images/raw/main/LogoEAP.png" width="500"/>

</center>

Profesor: <a href="http://www.pucp.edu.pe/profesor/jose-manuel-magallanes/" target="_blank">Dr. José Manuel MAGALLANES REYES, Ph.D.</a> <br>

-   Profesor del Departamento de Ciencias Sociales, Sección de Ciencia Política y Gobierno.

-   [Oficina 105](https://goo.gl/maps/xuGeG6o9di1i1y5m6) - Edificio CISEPA / ECONOMIA / CCSS

-   Telefono: (51) 1 - 6262000 anexo 4302

-   Correo Electrónico: [jmagallanes\@pucp.edu.pe](mailto:jmagallanes@pucp.edu.pe)

<a id='beginning'></a>

------------------------------------------------------------------------

<center>

<header>

<h2>

Modelando Variables Categóricas

</h2>

</header>

</center>


<center><a href="https://doi.org/10.5281/zenodo.7076490"><img src="https://zenodo.org/badge/DOI/10.5281/zenodo.7076490.svg" alt="DOI"></a>
</center>




------------------------------------------------------------------------

# Presentación

Michael Cowles y Carlone Davis prepararon una data para investigar quien es más proclive a ser voluntario en experimentos sociales [@cowles_subject_1987]. La data y la metadata están disponibles en [@arel-bundock_rdatasets_2022]. Veamos los contenidos:

```{r getdata}
rm(list = ls()) # clear memory
knitr::knit_hooks$set(inline = as.character) # inline as string

gitLink="https://vincentarelbundock.github.io/Rdatasets/csv/carData/Cowles.csv"
vol=read.csv(gitLink)[,-1] #no first column

# formatting:
vol[,c(3,4)]=lapply(vol[,c(3,4)],as.factor)

# display table
library(magrittr) # needed for pipe %>% 
vol%>%
    rmarkdown::paged_table()
```

Según la información proporcionada en el repositorio, esta es la metadata:

-   **neuroticism**: Una medida de inestabilidad emocional, los valores están en la escala de Eysenck [@eysenck_manual_1975].
-   **extraversion**: Una medida del interes por el mundo exterior de la gente y de las cosas, los valores están en la escala de Eysenck [@eysenck_manual_1975].
-   **sex**: una categoría con las modalidades: *female* y *male*.
-   **volunteer**: Un factor dicotómico que representa ser o no (*yes* o *no*) voluntario en experimentos sociales.

Esta investigación hipotetiza que:

> El ofrecerse como voluntario a experimentos sociales está relacionado con el sexo de la persona, su nivel de neuroticismo y su nivel de extraversión.

Hasta ahora hemos querido modelar hipotesis donde la variable dependiente eran valores continuos, y de conteos pero, como vemos, en esta hipótesis la variable dependiente es *volunteer* (ofrecerse como voluntario), la cuál es categórica (dicotómica). Esto no puede ser tratado con las técnicas anteriores [@magallanes_estadistica-analisispoliticosesion2_2022-1; @magallanes_estadistica-analisispoliticosesion3_2022].

Veamos un resumen univariado en la Tabla \@ref(tab:univarExploTabla).

```{r univarExploTabla, echo=TRUE}
library(summarytools)
library(kableExtra)

# usemos la función "dfSummary" de paquete "summarytools"
dfSummary(vol,
          plain.ascii  = FALSE,
          varnumbers = FALSE,
          style        = "grid", 
          graph.col=F,
          na.col    = FALSE) %>%
    kable(caption = "Descriptivos Univariados")%>%
    kable_styling(full_width = F)
```



# Probabilidades y ODDS

Hagamos un breve repaso de cómo usar tablas de contigencia para analizar variables categóricas. En este caso, analicemos la relación entre sexo del entrevistado y ser voluntario. Al ser ambas categóricas, y ser la hipótesis asimétrica o direccional, preparemos una tabla de contingencia que muestre ello. Veamos la Tabla \@ref(tab:tabconting).

```{r tabconting, echo=TRUE}
dep=vol$volunteer # a la fila
ind=vol$sex # a la columna

volsexTable=table(dep,ind,dnn = c('volunteer','sex'))

### suma por fila y columna
addmargins(volsexTable)%>%
    kable(caption = "Tabla de Contingencia: 'Sexo' y 'Ser Voluntario'")%>%
    kableExtra::kable_styling(full_width = F)

```
Recuérdese que se acostumbra que la variable independiente se sitúe en columnas, y la variable dependiente en filas. A partir de esta información tratemos de explorar la hipótesis:

> Ser mujer está relacionado con ser voluntario en proyectos de investigación.



Saber si *ser mujer* está relacionado con *ser voluntario* implica responderse:

-   Si elijo una mujer al azar, ¿qué probabilidad se tiene que ésta sea voluntaria?.
-   ¿Cómo comparo el "voluntarismo" de la mujer con el "voluntarismo" del hombre?

Para ello usaremos los conceptos de probabilidad, y en particular de Odds Ratio [@szumilas_explaining_2010]. Y todos los cálculos usarán los valores de la Tabla \@ref(tab:tabconting).

A. Probabilidad y Odds para caso de la mujer:

-   La **probabilidad** (entre 0 y 1) que una mujer sea voluntaria es la división del ser voluntaria entre el total de mujeres:

```{r, echo=TRUE}
ProbMujVol=volsexTable[2,1]/sum(volsexTable[,1])
MASS::fractions(ProbMujVol)
```

Es decir:

```{r, echo=TRUE}
ProbMujVol
```

-   Representemos el **odds** que sea voluntaria, la división entre ser o no ser voluntaria:

```{r, echo=TRUE}
OddsMujVol=volsexTable[2,1]/volsexTable[1,1]
MASS::fractions(OddsMujVol)
```

Es decir:

```{r, echo=TRUE}
OddsMujVol
```

El *odds* suele representarse además como la razón entre dos probabilidades: la probabilidad que *SÍ* ocurra un evento dividido por la probabilidad que *NO* ocurra ese evento:

```{r, echo=TRUE}
ProbMujVol/(1-ProbMujVol)
```

B. Probabilidad y Odds para caso del hombre:

-   Probabilidad que un hombre sea voluntario

```{r, echo=TRUE}
ProbHomVol=volsexTable[2,2]/sum(volsexTable[,2])
MASS::fractions(ProbHomVol)
```

O...

```{r, echo=TRUE}
ProbHomVol
```

Igual que antes, calculamos el odds:

```{r, echo=TRUE}
OddsHomVol=ProbHomVol/(1-ProbHomVol)
OddsHomVol
```

C. Comparando Mujer y Hombre:

Hasta aquí ya sabemos cuál odds ha salido mayor. Eso es información clara. Para precisar esa información, podemos dividir los odds, lo que nos da el **odds ratio**, que en este caso nos dirá *qué diferencia produce el sexo en el voluntariado*:

```{r, echo=TRUE}
(OR_MujHom=OddsMujVol/OddsHomVol)
```

Con ese valor, ya sabemos que el odds de ser mujer supera al odds del hombre por un factor de `r round(abs(1-OR_MujHom),2)`. El odds ratio (OR) puede ir de 0 a infinito. Un OR de 1 implica que no hay diferencias.

Veámoslo como fracción:

```{r, echo=TRUE}
MASS::fractions(OddsMujVol/OddsHomVol)
```

Si encuentras la cantidad de voluntarias del numerador, se espera la cantidad de voluntarios del denominador.

Veamos la tabla de contingencia (Tabla \@ref(tab:tabconting)) de manera gráfica en la Figura \@ref(fig:mosaic).

```{r mosaic, echo=TRUE, fig.cap="Tabla de Contingencia como Mosaico "}
mosaicplot( t(volsexTable),col = c("orange", "green"),main = "")
```

La diferencia es clara, pero ¿será ésta estadísticamente significativa?

# Regresión Logística Binaria

La regresión logística modela el comportamiento de la probabilidad del evento de interés, según vemos en la Ecuación \@ref(eq:logbin).

```{=tex}
\begin{equation}
{log}(\frac{{Y}}{{1 – Y}}) ={log}(\frac{{p(X)}}{{1 – p(X)}}) =\alpha  + \beta \cdot X + \epsilon (\#eq:logbin)
\end{equation}
```

La parte izquierda de la Ecuación \@ref(eq:logbin) representa esa probabilidad pero en términos del odds; y la parte derecha es igual a la ecuación de una recta, pero estamos modelando al logaritmo del odds. Veamos la Tabla \@ref(tab:rlog1).

```{r rlog1,warning=FALSE, message=FALSE, results='asis'}
### semilla
set.seed(2019)

### first hypothesis
h1=formula(volunteer~sex)

#regression
rlog1=glm(h1, data=vol,family = binomial)
modelrl=list('Ser Voluntario (I)'=rlog1)

#f <- function(x) format(x, digits = 4, scientific = FALSE)
library(modelsummary)
modelsummary(modelrl,
             title = "Regresión Logística",
             stars = TRUE,
             output = "kableExtra")

```

En general, se nota que el sexo (ser hombre) tiene efecto negativo y significativo sobre el logaritmo del odds de ser voluntario. Pero antes de ir a la interpretación detallada veamos otras consideraciones.

## Consideraciones Previas

La regresión  es sencilla de calcular, pero la presencia de variables categóricas puede traer complicaciones. Veamos cómo R está utilizando la variable dependiente:
```{r}
# la representación numérica
as.numeric(as.factor(c("no","yes")))
```
Qué pasaría si tuvieramos otras columnas:

```{r}
vol$IsVolunteer=ifelse(vol$volunteer=="yes",T,F)
vol$IsVolunteer_1=as.integer(ifelse(vol$volunteer=="yes",1,0))
vol$IsVolunteer_claro=as.factor(ifelse(vol$volunteer=="yes",
                             "claro","nunca"))

# nos queda:
library(magrittr)
vol[,c("volunteer","IsVolunteer","IsVolunteer_1","IsVolunteer_claro")]%>%
    rmarkdown::paged_table(options = )

```

Resscribamos la hipótesis inicial con las nuevas variables:

```{r}
h1b=formula(IsVolunteer~sex)
h1c=formula(IsVolunteer_1~sex)
h1d=formula(IsVolunteer_claro~sex)
```

Veamos:

* Dicotómica como Booleana (lógica)

```{r}
coef(glm(h1b, data=vol,family = binomial))
```
* Dicotómica como Entero:

```{r}
coef(glm(h1c, data=vol,family = binomial))
```

* Dicotómica como otras palabras

```{r}
coef(glm(h1d, data=vol,family = binomial))
```
Como se ve, R usa bien los casos Booleanos y de enteros, pero ante la presencia de otros textos en la respuesta sólo usará el orden alfabético.

Otro tema es el uso de categóricas en las variables independientes. El resultado anterior ha usado a **mujer como referencia**: nos informa cuánto afecta *ser hombre al logaritmo del odds de ser voluntario*, en comparación con ser mujer (la referencia). La Tabla \@ref(tab:rlog1) nos confirma que ser hombre disminuye (aquí el signo ayuda) el logaritmo del odds (y por ende la probabilidad) de ser voluntario. Veamos alternativamente la Tabla \@ref(tab:rlog1a) con la misma regresión pero con la categoría *hombre* como referencia.

```{r rlog1a, echo=TRUE}
# cambio de referencia
vol$sex=relevel(vol$sex,ref = "male")

#regresion
rlog1=glm(h1, data=vol,family = binomial)
modelrl=list('Ser Voluntario (I)'=rlog1)
modelsummary(modelrl,
             title = "Regresión Logística (con cambio de referencia en sexo)",
             stars = TRUE,
             output = "kableExtra")
```

La Tabla \@ref(tab:rlog1a), nos muestra el efecto (significativo al 0.05) positivo (nuevamente el signo ayuda) de ser mujer en ser voluntario .  

Recuerda que este tema de la categoría de referencia se aplica a todo tipo de regresión. 

## Interpretación

Los coeficientes de las Tablas \@ref(tab:rlog1)  y Tabla \@ref(tab:rlog1a), como modelan al logaritmo del odds, no son fáciles de interpretar. Pero, si le aplicamos exponencial obtendrás un odds ratio: veamos el caso del coeficiente`r round(coef(rlog1)["sexfemale"],3)` de la Tabla \@ref(tab:rlog1a):

```{r expCoefFem, echo=TRUE}
sexF=coef(rlog1)["sexfemale"]
exp(sexF)
```

Este valor ya lo conocíamos, pero ahora sabemos que el efecto de sexo es significativo gracias a la regresión logística, algo que no sabíamos con las tablas de contingencia. Lo que es más, sabemos que el hecho de ser mujer eleva en un factor de 0.28 al odds ratio de ser voluntario que si el entrevistado fuera hombre. 

Algo importante ahora es que con la regresión logística ya podemos tener predictores numéricos, lo que escapa de la utilidad de las tablas de contingencia. Así, podemos en el modelo II añadir una numérica a los predictores:

> El ofrecerse como voluntario está relacionado con el sexo de la persona, y su nivel de neuroticismo.

La Tabla \@ref(tab:rlog2) muestra los resultados para el modelo I y el II, ya con los coeficientes exponenciados:

```{r rlog2, echo=TRUE}
### second hypothesis
h2=formula(volunteer~sex + neuroticism)
rlog2=glm(h2, data=vol,family = binomial)

modelsrl=list('Ser Voluntario (I)'=rlog1,
             'Ser Voluntario (II)'=rlog2)

# formato creado para modelsummary
formatoNumero = function(x) format(x, digits = 4, scientific = FALSE)
modelsummary(modelsrl,
             fmt=formatoNumero, # usa función que creé antes
             exponentiate = T, # coeficientes sin logaritmo
             statistic = 'conf.int', # mostrar ICs
             title = "Regresión Logísticas (Coeficientes Exponenciados)",
             stars = TRUE,
             output = "kableExtra")

```

En el modelo II notamos que el efecto de ser mujer disminuye, pero no mucho. Probemos ahora el modelo III, el que completa la hipótesis de los investigadores:

> El ofrecerse como voluntario está relacionado con el sexo de la persona, su nivel de neuroticismo y su nivel de extraversión.

Veamos lo en simple:

```{r rlog3}
h3=formula(volunteer~sex + neuroticism + extraversion)
rlog3=glm(h3, data=vol,family = binomial)

summary(rlog3)
```


Ahora, a todos los modelos juntos \@ref(tab:rlogALL):

```{r rlogALL, echo=TRUE}

modelsrl=list('Ser Voluntario (I)'=rlog1,
             'Ser Voluntario (II)'=rlog2,
             'Ser Voluntario (III)'=rlog3)

f <- function(x) format(x, digits = 4, scientific = FALSE)
modelsummary(modelsrl,
             fmt=formatoNumero,
             exponentiate = T, 
             statistic = 'conf.int',
             title = "Comparando Regresión Logísticas (Coeficientes Exponenciados)",
             stars = TRUE,
             gof_map = c("nobs","aic","bic","rmse","logLik"), #comparar
             gof_omit = c("F"),
             output = "kableExtra")
```



Del modelo III tenemos que:

* Tres coeficientes son mayores que *uno* (podrían tener un efecto positivo, pero falta revisar otra información).
* El intervalo de confianza de la *neuroticism* incluye al 1.[^1]
* El p-valor de *neuroticism* es mayor a 0.1 (la probabilidad que sea 1 -no tenga efecto- es mayor al 10%, lo que contribuye a aceptar que no tendría efecto), por lo que lo consideramos no significativo.

[^1]: Al igual que en la Poisson, no queremos que el intervalo de confianza incluya el *uno*.

El coeficiente de la variable sexo con hombre como referencia es:
```{r}
round(exp(coef(rlog3)["sexfemale"]),4)
```
Ese número es el factor por el que se multiplica en promedio el odds ratio de ser voluntario cuando se es mujer, o dicho de otra manera el odds ratio de ser voluntario se eleva en este procentaje:
```{r}
100*round(abs(1-exp(coef(rlog3)["sexfemale"])),4)
```

De manera similar, el coeficiente de la variable extraversión es:

```{r}
round(exp(coef(rlog3)["extraversion"]),4)
```
Ese número es el factor por el que se multiplica en promedio el odds ratio de ser voluntario cada vez que la escala de extroversión aumenta en uno, o dicho de otra manera el odds ratio de ser voluntario se eleva en este porcentaje cada vez que la escala de extroversión aumenta en uno:
```{r}
100*round(abs(1-exp(coef(rlog3)["extraversion"])),4)
```

Podemos calcular los coeficientes estandarizados [@ibm_spss_computing_2020] para saber cuál de los predictores del modelo III tiene mayor efecto (ver Tabla \@ref(tab:stdCoefs)).

```{r stdCoefs}
vol$sexFem_num=ifelse(vol$sex=='male',0,1) # 1 es para mujer
sdVIs=apply(vol[,c("sexFem_num","neuroticism", "extraversion")],2,sd)
DF=list(LogitSt=sdVIs*coef(rlog3)[c(2,3,4)])%>%
       data.frame()

# DF tiene los coeficientes estandarizados

DF%>% kable(caption = "Coeficientes Estandarizados (ordenar vía valores absolutos)")%>%
          kableExtra::kable_styling(full_width = F)

```

Usando valores absolutos notamos cuál es el orden de importancia, en este caso *extraversion* es la que más efecto tiene. Pero no usemos esos valores para interpretar el efecto numérico, sólo saber cuál afecta más que otro.

## Decidiendo mejor modelo

R entrega algunos índices muy para comparar los modelos logísticos, el BIC, AIC, RMSE[^2], y Log.Lik. Los primeros tres indican que el modelo es mejor si tienen valores bajos; mientras que el último será mejor si su valor aumenta. 

[^2]: Nota que RMSE se mantiene constante (al menos con las cifras mostradas).

Sin embargo, las diferencias pueden ser mínimas entre estos índices, por lo que es apropiado usar el test de razón de verosimilitud (likelihood ratio test -LRT), cuyo resultado lo vemos en la Tabla \@ref(tab:LRTall).

```{r LRTall, message=FALSE}

library(lmtest)

lrtest(rlog1,rlog2, rlog3) %>%
kable(caption = "Tabla LRT para comparar modelos")%>%kableExtra::kable_styling(full_width = FALSE)
```

Como vemos en la Tabla \@ref(tab:LRTall), pasar del modelo 1 al modelo 2 es no significativo (probabilidad de similitud es más de 90%), por lo que no se rechaza la hipotesis nula de igualdad de modelos. Pero sí es significativo pasar del modelo 2 al modelo 3.

Podemos comparar los modelos I, II, y III de manera gráfica en la Figura \@ref(fig:finplots).

```{r finplots, fig.cap="Comparación visual de modelos", message=FALSE, warning=FALSE}
library(ggplot2)
dotwhisker::dwplot(list(Logit_I=rlog1,Logit_II=rlog2,Logit_III=rlog3),
                   exp=T) + #exponenciados!
            scale_y_discrete(labels=c("extraversion",
                                      "neuroticism",
                                      "sex (ref: male)")) +
            scale_color_discrete(name="Modelos para:\nSer Voluntario") +
            geom_vline(xintercept = 1,
                       colour = "grey60",
                       linetype = 2)
```

En la Figura \@ref(fig:finplots) se nota claramente por qué el neuroticismo no es significativo.

## Evaluando modelo seleccionado

Cuando usamos una regresión logística queremos predecir probabilidades, en este caso, ante una combinación de los predictores **X**, qué **probabilidad** se obtiene con esta regresión para ser voluntario. Esos son los valor **ajustados** (*fitted*) que te entrega el modelo, y nos servirá para evaluar si nos hemos acercado al **Y** original. Calculemos tales probabilidades:

```{r}
predictedProbs <- predict(rlog3, vol,type = "response")
# veamos algunos de ellos
head(predictedProbs)
```
Aquí podemos usar estos valores para crear el 0 o 1 predicho:
```{r}
vol$predicted=ifelse(predictedProbs>0.5,"yes","no")
```

Veamos algunas filas de estas dos columnas:
```{r}
head(vol[,c("predicted","volunteer")],10)
```

La columns *predicted* busca ser la misma que la columna *volunteer*, pero en algunos casos puede fallar. 

Para saber qué tanto se acertó creamos una  Matriz de Confusión  [@suresh_what_2021] usando el paquete **cvms** [^3] en la Figura \@ref(fig:plotConfusionMatrix).

```{r plotConfusionMatrix, fig.cap="Matriz de confusión", message=FALSE, warning=FALSE}

library(cvms)
ConfMatrix=confusion_matrix(predictions =  vol$predicted,
                      targets= vol$volunteer)
library(cvms)
plot_confusion_matrix(ConfMatrix,
                      class_order=c("yes","no"))
```
 [^3]: Para evitar mensajes de advertencia, instale además 'ggimage'  y 'rsvg', luego de intala 'cvms'.



La diagonal secundaria o antidiagonal debería tener sólo 0s si tuviésemos una predicción perfecta, y los demás valores estar en la diagonal principal. El modelo, debería servir para reducir sustantivamente ese error. 

Note que en la matriz de confusión se puede calcular valores clave [@trevethan_sensitivity_2017]:

* Verdaderos Positivos (VP)

* Verdaderos Negativos (VN)

* Falsos Positivo (FP)

* Falsos Negativos (FN)

Y a partir de ellos:

* La **Sensitividad** (VP/(VP+FN)): Utilidad del modelo para determinar el "voluntario" (modelo predice a un voluntario que realmente era voluntario en la data original').

```{r}
ConfMatrix$Sensitivity
```
*   La **Especificidad** (VN/(VN+FP)): Utilidad del modelo para determinar el "no voluntario" (modelo predice a un no voluntario que realmente no era voluntario en la data original').

```{r}
ConfMatrix$Specificity
```
Una medida general es el índice de Kappa:

```{r}
ConfMatrix$Kappa
```

Este índice vale **1** si la predicción es perfecta, y **0** si fallan todas las predicciones. 

## Prediciendo valores concretos

Si nos quedamos con el modelo III, podemos utilizarlo para predicciones. Veamos:

-   Ejemplo 1: Predecir probabilidad de voluntariado de una mujer con nivel de neuroticismo=13 y extraversion=8:

```{r predict1, echo=TRUE}
ToInput1 <- data.frame(sex=factor(c("female")), 
                      neuroticism=13, extraversion=8)
predict(object = rlog3, newdata = ToInput1, type = "response")
```

-   Ejemplo 2: Predecir probabilidad de voluntariado de una mujer y hombre con los mismos niveles anteriores de neuroticismo y extraversion.

```{r predict2, echo=TRUE}
ToInput2 <- data.frame(sex=factor(c("female","male")), 
                      neuroticism=13, extraversion=8)
predict(object = rlog3, newdata = ToInput2, type = "response")
```

-   Ejemplo 3: Predecir probabilidad de voluntariado de dos mujeres, con nivel de neuroticismo de 13 y 10, y extraversion de 8 y 21, respectivamente:

```{r predict3, echo=TRUE}
ToInput3 <- data.frame(sex=factor(c("female","female")), 
                      neuroticism=c(13,10), extraversion=c(8,21))
predict(object = rlog3, newdata = ToInput3, type = "response")
```

## Efectos Marginales

Recuerdese que tenemos en **predicted** las probabilidades de cada caso:

```{r}
head(vol$predicted)
```

Pero NO sabemos cuando afecta cada variable la probabilidad de ser voluntario en promedio. Para ello pedimos efectos marginales [@ford_beginners_2022], los que podemos ver en la Tabla \@ref(tab:marginals-table)

```{r  marginals-table, message=FALSE}
# interpracion usando marginal effects:
library(margins)
# 

marginalsData=summary(margins(rlog3)) 
marginalsData%>% kable(caption = "Efectos Marginales Promedio (AME)- Modelo III") %>%kableExtra::kable_styling(full_width = T)

```

La Tabla \@ref(tab:marginals-table) nos indica, por ejemplo, que en promedio, el incremento de un punto en la variable *extraversion* aumenta en `r round(marginalsData$AME[['extraversion']],6)` ^[También podría usar los valores del intervalo de confianza de los AME en tu interpretación.] la probabilidad de ser voluntario. Los valores de la Tabla \@ref(tab:marginals-table) podemos verlos gráficamente en la Figura \@ref(fig:marginals-plot).

```{r marginals-plot, fig.cap="Efectos Marginales Promedio (AME)"}
library(ggplot2)
base= ggplot(marginalsData,aes(x=factor, y=AME)) + geom_point()
base +  geom_errorbar(aes(ymin=lower, ymax=upper))
```

------------------------------------------------------------------------

# Bibliografía {.unnumbered}

::: {#refs}
:::

<br></br> <br></br> [al INICIO](#beginning) <br></br> <br></br>
